{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057492c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c84fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import cvxpy as cp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Basic settings\n",
    "# -----------------------------------------------------------------------------\n",
    "block_qubits_num = 2  # num of qubits in block (example)\n",
    "block_dim = 2**block_qubits_num  # also num of occpumational numbers\n",
    "t_factor = 6          # extension multiplier (example)\n",
    "basis_dim = math.comb(block_dim + t_factor - 1, block_dim - 1)  # basis dimentions in bosonic system\n",
    "\n",
    "\n",
    "def one_qubit_operator_X_Z(angle=np.pi / 4):\n",
    "    \"\"\"\n",
    "    Generates a mixture of Pauli-X and Pauli-Z operators on a single qubit.\n",
    "\n",
    "    Parameters:\n",
    "        angle (float): The angle parameterizing the mixture. Default is π/4.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2x2 matrix representing the operator.\n",
    "    \"\"\"\n",
    "    if not isinstance(angle, (int, float)):\n",
    "        raise ValueError(\"angle must be a numeric value.\")\n",
    "    return np.array([[np.sin(angle), np.cos(angle)],\n",
    "                     [np.cos(angle), -np.sin(angle)]])\n",
    "\n",
    "\n",
    "def plot_colormap(array):\n",
    "    \"\"\"\n",
    "    Plot a 2D array as a colormap.\n",
    "    Parameters:\n",
    "        array (list of lists or numpy array)\n",
    "    \"\"\"\n",
    "    array = np.array(array)\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.imshow(array, cmap='viridis')\n",
    "    fig.colorbar(cax)\n",
    "    plt.show()\n",
    "\n",
    "def opnorm_inf(H: np.ndarray) -> float:\n",
    "    # spectral norm; for Hermitian equals max|eig|\n",
    "    if np.allclose(H, H.conj().T):\n",
    "        return float(np.max(np.abs(np.linalg.eigvalsh(H))))\n",
    "    return float(np.linalg.svd(H, compute_uv=False).max())\n",
    "\n",
    "def normalize_single_copy(H: np.ndarray):\n",
    "    s = opnorm_inf(H)\n",
    "    return (H / s if s > 0 else H), (s if s > 0 else 1.0)\n",
    "\n",
    "# {I,X,Y,Z}x{I,X,Y,Z}={I,IX,IY,IZ,XI,XY,XZ,YI,YX,YY,YZ,ZI,ZX,ZY,ZZ} simpler if real only\n",
    "# Pauli bases\n",
    "I = np.eye(2, dtype=complex)\n",
    "X = np.array([[0,1],[1,0]], dtype=complex)\n",
    "Y = np.array([[0,-1j],[1j,0]], dtype=complex)\n",
    "Z = np.array([[1,0],[0,-1]], dtype=complex)\n",
    "CP = np.diag([1, 1, 1, -1])\n",
    "\n",
    "pool_1q = [\"I\", \"X\", \"Y\", \"Z\"]\n",
    "all_matrices_keys = [i + j for i in pool_1q for j in pool_1q]\n",
    "pool_1q = [I, X, Y, Z]\n",
    "M = dict.fromkeys(all_matrices_keys + [\"CP\"], 0)\n",
    "pool_2q = [np.kron(i, j) for i in pool_1q for j in pool_1q]\n",
    "pool_2q.append(CP)\n",
    "a = 0\n",
    "for k in M.keys():\n",
    "    M[k] = pool_2q[a]\n",
    "    a += 1\n",
    "\n",
    "\n",
    "# working with bosonic basis\n",
    "def global_basis_states(multipl=t_factor, block=block_dim, dictionary=False):\n",
    "    \"\"\"\n",
    "    Generates a list of bosonic states for a given number of qubits and multiplier.\n",
    "\n",
    "    Parameters:\n",
    "        multipl (int): The multiplier (t_embedding). Default is t_factor.\n",
    "        block (int): The number of qubits. Default is block_dim.\n",
    "        dictionary (bool): If True, returns a dictionary with states as keys. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: A list of compositions or a tuple (compositions, dictionary).\n",
    "    \"\"\"\n",
    "    bars = combinations(range(multipl + block - 1), block - 1)\n",
    "\n",
    "    compositions = []\n",
    "    for bar in bars:\n",
    "        bar_positions = [-1] + list(bar) + [multipl + block - 1]\n",
    "        composition = tuple(bar_positions[i + 1] - bar_positions[i] - 1 for i in range(block))\n",
    "        compositions.append(composition)\n",
    "\n",
    "    compositions.reverse()\n",
    "\n",
    "    if dictionary:\n",
    "        return compositions, dict.fromkeys(compositions, 0)\n",
    "    return compositions\n",
    "\n",
    "def one_qubit_stabilizers():\n",
    "    z0 = np.array([1,0], dtype=complex)\n",
    "    z1 = np.array([0,1], dtype=complex)\n",
    "    xp = (z0+z1)/np.sqrt(2); xm = (z0-z1)/np.sqrt(2)\n",
    "    yp = (z0+1j*z1)/np.sqrt(2); ym = (z0-1j*z1)/np.sqrt(2)\n",
    "    return [z0,z1,xp,xm,yp,ym]\n",
    "\n",
    "def two_qubit_stabilizer_states():\n",
    "    paulis = [I,X,Y,Z]\n",
    "    twopaulis = [np.kron(a,b) for a in paulis for b in paulis]\n",
    "    twopaulis = [P for P in twopaulis if not np.allclose(P, np.eye(4))]\n",
    "    states = []\n",
    "    seen = set()\n",
    "    Id4 = np.eye(4, dtype=complex)\n",
    "    for i in range(len(twopaulis)):\n",
    "        P1 = twopaulis[i]\n",
    "        for j in range(i+1, len(twopaulis)):\n",
    "            P2 = twopaulis[j]\n",
    "            if not np.allclose(P1@P2, P2@P1): \n",
    "                continue\n",
    "            # +1 eigenspace projector\n",
    "            P = (Id4 + P1)/2 @ (Id4 + P2)/2\n",
    "            A = (P + P.conj().T)/2\n",
    "            w, V = np.linalg.eigh(A)\n",
    "            k = int(np.argmax(w))\n",
    "            if w[k] > 1-1e-9:  # rank-1\n",
    "                psi = V[:,k] / np.linalg.norm(V[:,k])\n",
    "                rho = np.outer(psi, psi.conj())\n",
    "                key = (np.round(rho.real,8).tobytes(), np.round(rho.imag,8).tobytes())\n",
    "                if key not in seen:\n",
    "                    seen.add(key); states.append(psi)\n",
    "    return states  # should be 60\n",
    "\n",
    "def s_stab_singlecopy(W1: np.ndarray, n_qubits: int) -> float:\n",
    "    if n_qubits == 1:\n",
    "        S = one_qubit_stabilizers()\n",
    "        return max(np.real(np.vdot(psi, W1 @ psi)) for psi in S)\n",
    "    elif n_qubits == 2:\n",
    "        S = two_qubit_stabilizer_states()\n",
    "        return max(np.real(np.vdot(psi, W1 @ psi)) for psi in S)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only n=1,2 stabilizer enumeration provided.\")\n",
    "\n",
    "def aidaj(index1, index2, vector):\n",
    "    \"\"\"\n",
    "    Action of the operator (a_i^\\dagger)(a_j) on a given vector.\n",
    "\n",
    "    Parameters:\n",
    "        index1 (int): The index for the creation operator.\n",
    "        index2 (int): The index for the annihilation operator.\n",
    "        vector (tuple or list): The input vector.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new vector and the coefficient.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(vector, (tuple, list)):\n",
    "        raise TypeError(\"vector must be a tuple or list.\")\n",
    "    if not all(isinstance(x, int) for x in vector):\n",
    "        raise TypeError(\"All elements of vector must be integers.\")\n",
    "    if index1 >= len(vector) or index2 >= len(vector) or index1 < 0 or index2 < 0:\n",
    "        raise ValueError(\"Indices out of range.\")\n",
    "\n",
    "    # If the annihilation operator acts on a zero element, return the original vector and zero coefficient\n",
    "    if vector[index2] == 0:\n",
    "        return vector, 0\n",
    "\n",
    "    # Compute the new vector and coefficient\n",
    "    v = list(vector)\n",
    "    c = np.sqrt(v[index2])\n",
    "    v[index2] -= 1\n",
    "    c *= np.sqrt(v[index1] + 1)\n",
    "    v[index1] += 1\n",
    "\n",
    "    return tuple(v), c\n",
    "\n",
    "\n",
    "def build_embedded_matrix(H, block_dim=2, size=6):\n",
    "    \"\"\"\n",
    "    Constructs an embedded matrix from a given operator H in a bosonic basis.\n",
    "\n",
    "    Parameters:\n",
    "        H (np.ndarray): Matrix of size block_dim x block_dim.\n",
    "        block_dim (int): The dimension of the matrix. Default is 2.\n",
    "        size (int): The scale parameter for the bosonic basis. Default is 6.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The embedded matrix of size basis_dim x basis_dim.\n",
    "    \"\"\"\n",
    "    if not isinstance(H, np.ndarray) or H.shape != (block_dim, block_dim):\n",
    "        raise ValueError(\"H must be a square matrix of size block_dim x block_dim.\")\n",
    "    if not isinstance(size, int) or size <= 0:\n",
    "        raise ValueError(\"size must be a positive integer.\")\n",
    "\n",
    "    basis_dim_local = math.comb(block_dim + size - 1, block_dim - 1)\n",
    "    basis, _ = global_basis_states(multipl=size, block=block_dim, dictionary=True)\n",
    "    H, _ = normalize_single_copy(H)\n",
    "    embedded = np.zeros((basis_dim_local, basis_dim_local), dtype=np.complex128)\n",
    "\n",
    "    for k in range(basis_dim_local):\n",
    "        vector = dict.fromkeys(basis, 0)\n",
    "        for i in range(block_dim):\n",
    "            for j in range(block_dim):\n",
    "                if H[i][j] != 0:\n",
    "                    new_state, coeff = aidaj(i, j, basis[k])\n",
    "                    vector[new_state] += coeff * H[i][j]\n",
    "        for l in range(basis_dim_local):\n",
    "            embedded[k][l] = vector[basis[l]]\n",
    "    return embedded / size\n",
    "\n",
    "\n",
    "# support structures for antiidentity operations:\n",
    "def reference_binary(block_size=block_qubits_num):\n",
    "    \"\"\"\n",
    "    Generates a reference matrix and vocabulary for all possible binary states of a given number of qubits.\n",
    "\n",
    "    Parameters:\n",
    "        block_size (int): The number of qubits. Default is block_qubits_num.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ref_matrix, ref_vocab)\n",
    "    \"\"\"\n",
    "    if not isinstance(block_size, int) or block_size <= 0:\n",
    "        raise ValueError(\"block_size must be a positive integer.\")\n",
    "\n",
    "    num_states = 2**block_size\n",
    "    binary_states = [tuple(int(bit) for bit in bin(i)[2:].zfill(block_size)) for i in range(num_states)]\n",
    "    ref_matrix = np.array(binary_states)\n",
    "    ref_vocab = {state: idx for idx, state in enumerate(binary_states)}\n",
    "    return ref_matrix, ref_vocab\n",
    "\n",
    "\n",
    "def swapper(obj, reference, reference_vec):\n",
    "    \"\"\"\n",
    "    Performs a swapping operation on the input object based on a reference matrix and vocabulary.\n",
    "\n",
    "    Parameters:\n",
    "        obj (list or tuple): The input object.\n",
    "        reference (np.ndarray): The reference matrix.\n",
    "        reference_vec (dict): A dictionary mapping binary states to their indices.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The swapped object.\n",
    "    \"\"\"\n",
    "    swp_indx = []\n",
    "    output = []\n",
    "    length = len(obj)\n",
    "    width = len(reference[0])\n",
    "\n",
    "    for j in range(width):\n",
    "        swp_indx.append(0)\n",
    "        for i in range(length):\n",
    "            swp_indx[j] += obj[i] * reference[i][j]\n",
    "        swp_indx[j] %= 2\n",
    "\n",
    "    for i in range(length):\n",
    "        temp = reference[i].copy()\n",
    "        for j in range(width):\n",
    "            temp[j] = (swp_indx[j] + temp[j]) % 2\n",
    "        output.append(obj[reference_vec[tuple(temp)]])\n",
    "    return tuple(output)\n",
    "\n",
    "\n",
    "def AnId_lesdim_1(obj, reference, reference_vec, AId_dim=6, t_factor=6):\n",
    "    \"\"\"\n",
    "    Computes the action of a specific-dimension anti-identity operation on the input object.\n",
    "\n",
    "    Parameters:\n",
    "        obj (list or tuple): The input object.\n",
    "        reference (np.ndarray): The reference matrix.\n",
    "        reference_vec (dict): A dictionary mapping binary states to their indices.\n",
    "        AId_dim (int or str): The dimensionality of the anti-identity operation. Default is \"Max\".\n",
    "        t_factor (int): The size parameter for the bosonic basis. Default is t_factor.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of transformed objects.\n",
    "    \"\"\"\n",
    "    # input check\n",
    "    if AId_dim % 6 != 0 and AId_dim > 0:\n",
    "        raise TypeError(\"Antiidentity generator dimension must be positive multiples of 6\")\n",
    "    if t_factor < AId_dim:\n",
    "        raise TypeError(\"Antiidentity generator dimension must not be larger then number of copies\")\n",
    "    counter2 = 0\n",
    "    for x in obj:\n",
    "        if x < 0:\n",
    "            raise TypeError(\"negative values in object\")\n",
    "        counter2 += x\n",
    "    if counter2 != t_factor:\n",
    "        raise TypeError(\"wrong object: wrong number of entries detected\")\n",
    "\n",
    "    variants = list(combinations(range(t_factor), AId_dim))\n",
    "    output = []\n",
    "\n",
    "    for comb in variants:\n",
    "        restrained_vector = np.zeros_like(obj)\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "\n",
    "        for i in range(len(obj)):\n",
    "            for _ in range(obj[i]):\n",
    "                if counter1 == comb[counter2]:\n",
    "                    counter2 += 1\n",
    "                    restrained_vector[i] += 1\n",
    "                    if counter2 >= AId_dim:\n",
    "                        break\n",
    "                counter1 += 1\n",
    "            if counter2 >= AId_dim:\n",
    "                break\n",
    "\n",
    "        counter2 = 0\n",
    "        for i in range(len(obj)):\n",
    "            for _ in range(obj[i]):\n",
    "                counter2 += 1\n",
    "        if counter2 != t_factor:\n",
    "            raise TypeError(\"wrong object: wrong number of entries detected\")\n",
    "\n",
    "        swapped_vector = list(swapper(restrained_vector, reference=reference, reference_vec=reference_vec))\n",
    "        result = tuple(np.array(obj) - restrained_vector + swapped_vector)\n",
    "        output.append(result)\n",
    "\n",
    "    return set(output)\n",
    "\n",
    "\n",
    "def multinomial_coeff(a):\n",
    "    \"\"\"\n",
    "    computes a multinomial coefficient (number of computational states mixed in bosonic state)\n",
    "\n",
    "    Parameter:\n",
    "        a (tuple, int): bosonic basis state.\n",
    "\n",
    "    Returns:\n",
    "        integer: coefficient\n",
    "    \"\"\"\n",
    "    T = sum(a)\n",
    "    log_coeff = math.lgamma(T + 1)  # ln(T!)\n",
    "    for num in a:\n",
    "        log_coeff -= math.lgamma(num + 1)  # Subtract ln(num!)\n",
    "    return round(math.exp(log_coeff))  # Convert back to integer\n",
    "\n",
    "\n",
    "def orbit_counting(t_multiplier=t_factor, qubit_num=block_qubits_num, AnId_dim_set=[6], verbose=True, only_orbits=False):\n",
    "    \"\"\"\n",
    "    Constructs orbits induced by anti-identities of specified set of dimensions, creates a conversion matrix.\n",
    "\n",
    "    Parameters:\n",
    "        t_multiplier (int): The size parameter for the bosonic basis. Default is t_factor.\n",
    "        qubit_num (int): The number of qubits. Default is block_qubits_num.\n",
    "        AnId_dim_set (list): A list of dimensions for the anti-identity operations. Default is [\"Max\"].\n",
    "        verbose (bool): If True, prints progress information. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - orbits (dict): A dictionary mapping orbit numbers to sets of basis states.\n",
    "            - basis_orbit_index (list): A list mapping basis states to orbit numbers.\n",
    "            - basis (list): The list of basis states.\n",
    "            - basis_dict (dict): A dictionary mapping basis states to their indices.\n",
    "            - conversion_matrix (np.ndarray): The conversion matrix for transforming to the reduced basis.\n",
    "    \"\"\"\n",
    "    block = 2**qubit_num\n",
    "    basis, basis_dict = global_basis_states(t_multiplier, block, True)\n",
    "    for i in range(len(basis)):\n",
    "        basis_dict[basis[i]] = i\n",
    "\n",
    "    reference_matrix, reference_vector = reference_binary(block_size=qubit_num)\n",
    "\n",
    "    basis_orbit_index = [-1] * len(basis)\n",
    "    basis_state_weight = np.zeros(len(basis))  # !!!!#\n",
    "    orbits = {}\n",
    "    orbit_number = 0\n",
    "    inorbits = set()\n",
    "    current = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(\"orbit counting for \", t_multiplier, \"copies, of \", qubit_num, \"qubits\")\n",
    "    progress = tqdm(desc=\"counting...\", unit=\"step\", total=len(basis), mininterval=1, disable=not verbose)\n",
    "\n",
    "    while current < len(basis):\n",
    "        if current in inorbits:\n",
    "            current += 1\n",
    "            continue\n",
    "\n",
    "        q = {current}\n",
    "        newq = set(q)\n",
    "\n",
    "        while len(newq) > 0:\n",
    "            qq = set(newq)\n",
    "            newq = set()\n",
    "            for i in qq:\n",
    "                for aiid in AnId_dim_set:\n",
    "                    A = AnId_lesdim_1(\n",
    "                        basis[i],\n",
    "                        reference=reference_matrix,\n",
    "                        reference_vec=reference_vector,\n",
    "                        AId_dim=aiid,\n",
    "                        t_factor=t_multiplier,\n",
    "                    )\n",
    "                    for j in A:\n",
    "                        tem = basis_dict[j]\n",
    "                        if tem not in q:\n",
    "                            newq.add(tem)\n",
    "            q.update(newq)\n",
    "\n",
    "        inorbits.update(q)\n",
    "        orbits.update({orbit_number: q})\n",
    "        for y in q:\n",
    "            basis_orbit_index[y] = orbit_number\n",
    "\n",
    "        current += 1\n",
    "        orbit_number += 1\n",
    "        progress.update(len(q))\n",
    "    progress.close()\n",
    "    if only_orbits: \n",
    "        print( \"new basis dim =\", len(orbits), \"/ old basis dim :\",len(basis) )\n",
    "        return orbits, basis_orbit_index\n",
    "    # create conversion matrix\n",
    "    state_weights = np.zeros(len(basis))  # weights in orbits vector for bosonic states\n",
    "    for orbi in orbits:  # going over all orbits\n",
    "        orbit_weight = 0  # total orbit weight reset\n",
    "        for j in orbits[orbi]:  # going over all bosonic states in the current orbit\n",
    "            state_weights[j] = multinomial_coeff(basis[j])      # initial weight\n",
    "            orbit_weight += state_weights[j]\n",
    "        for j in orbits[orbi]:\n",
    "            state_weights[j] = np.sqrt(state_weights[j] / orbit_weight)\n",
    "\n",
    "    conversion_matrix = np.zeros((len(orbits), len(basis)))\n",
    "    for i in range(len(basis)):\n",
    "        conversion_matrix[basis_orbit_index[i]][i] = state_weights[i]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"new basis dim =\", len(conversion_matrix), \"/ old basis dim :\", len(conversion_matrix[0])) \n",
    "\n",
    "    return orbits, basis_orbit_index, basis, basis_dict, conversion_matrix\n",
    "\n",
    "\n",
    "def reduce_embedded(embedded_matrix, conversion_matrix):\n",
    "    \"\"\"\n",
    "    Converts an embedded matrix to a reduced basis using a conversion matrix.\n",
    "\n",
    "    Parameters:\n",
    "        embedded_matrix (np.ndarray): The embedded matrix to be reduced.\n",
    "        conversion_matrix (np.ndarray): The conversion matrix for the basis transformation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reduced matrix.\n",
    "    \"\"\"\n",
    "    if not isinstance(embedded_matrix, np.ndarray) or len(embedded_matrix.shape) != 2:\n",
    "        raise TypeError(\"embedded_matrix must be a 2D numpy array.\")\n",
    "    if not isinstance(conversion_matrix, np.ndarray) or len(conversion_matrix.shape) != 2:\n",
    "        raise TypeError(\"conversion_matrix must be a 2D numpy array.\")\n",
    "    if embedded_matrix.shape[1] != conversion_matrix.shape[1]:\n",
    "        raise ValueError(\"The number of columns in embedded_matrix must match the number of columns in conversion_matrix.\")\n",
    "\n",
    "    identity_check = conversion_matrix @ np.transpose(conversion_matrix)\n",
    "    identity_matrix = np.eye(len(identity_check))\n",
    "    if not np.allclose(identity_check, identity_matrix, atol=1e-5):\n",
    "        raise ValueError(\"The conversion matrix is not orthogonal.\")\n",
    "    reduced_matrix = conversion_matrix @ embedded_matrix @ np.transpose(conversion_matrix)\n",
    "    return reduced_matrix\n",
    "\n",
    "\n",
    "def Convex_problem_run(\n",
    "    initstate,\n",
    "    block_qubits=block_qubits_num,\n",
    "    multiplier=t_factor,\n",
    "    Verbose=False,\n",
    "    Antiid_dim_set=[6],\n",
    "    canon_backend=cp.SCIPY_CANON_BACKEND,\n",
    "    solver=cp.SCS,\n",
    "    complexity=True,\n",
    "):\n",
    "    \"\"\"\n",
    "                        << Convex optimization problem >>\n",
    "\n",
    "    Parameters:\n",
    "        initstate (np.ndarray): initial operator\n",
    "        block_qubits (int): The number of qubits in a block. Default is block_qubits_num.\n",
    "        multiplier (int): The scaling parameter the bosonic basis. Default is t_factor.\n",
    "        Verbose (bool): If True, prints progress information. Default is False.\n",
    "        Antiid_dim_set (list): A list of dimensions for the anti-identity. Default is [6].\n",
    "        canon_backend: The canonicalization backend for cvxpy. Default is cp.SCIPY_CANON_BACKEND.\n",
    "        solver: The solver for cvxpy. Default is cp.SCS.\n",
    "        complexity (bool): If True, uses complex-valued variables. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        ---------\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Perform orbit counting\n",
    "    orbits, basis_orbit_index, basis, basis_dict, conversion_matrix = orbit_counting(\n",
    "        t_multiplier=multiplier, qubit_num=block_qubits, AnId_dim_set=Antiid_dim_set, verbose=Verbose\n",
    "    )\n",
    "\n",
    "    # Build and reduce the embedded matrix\n",
    "    embedded_matrix = build_embedded_matrix(initstate, block_dim=2**block_qubits, size=multiplier)\n",
    "    reduced_embedded_matrix = reduce_embedded(embedded_matrix, conversion_matrix=conversion_matrix)\n",
    "\n",
    "    # Set up the convex optimization problem\n",
    "    if complexity and Verbose:\n",
    "        print(\"solving with complex values\")\n",
    "\n",
    "    if complexity:\n",
    "        current_var = cp.Variable((len(orbits), len(orbits)), hermitian=True)\n",
    "        constraints = [cp.trace(current_var) == 1, current_var >> 0]\n",
    "        objective = cp.real(cp.trace(reduced_embedded_matrix @ current_var))\n",
    "    else:\n",
    "        current_var = cp.Variable((len(orbits), len(orbits)), PSD=True)\n",
    "        constraints = [cp.trace(current_var) == 1]\n",
    "        # Avoid cp.real on a real expression in CVXPY\n",
    "        objective = cp.trace(reduced_embedded_matrix @ current_var)\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(objective), constraints)\n",
    "    setup_time = time.time() - start\n",
    "\n",
    "    sol = prob.solve(canon_backend=canon_backend, solver=solver, verbose=Verbose)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if Verbose:\n",
    "        print(f\"Total time: {end_time - start} s (setup: {setup_time} s; solver call: {end_time - start - setup_time} s)\")\n",
    "        print(f\"Optimal value: {sol}\")\n",
    "        print(f\"Trace of reduced embedded matrix: {np.trace(reduced_embedded_matrix)}\")\n",
    "\n",
    "    return (\n",
    "        sol,\n",
    "        current_var.value,\n",
    "        np.linalg.norm(current_var.value),\n",
    "        np.linalg.norm(reduced_embedded_matrix),\n",
    "        np.linalg.norm(reduced_embedded_matrix, ord=2),\n",
    "    )\n",
    "\n",
    "\n",
    "def split_convex_setup(\n",
    "    block_qubits=block_qubits_num,\n",
    "    multiplier=t_factor,\n",
    "    Verbose=False,\n",
    "    Antiid_dim_set=[6],\n",
    "    canon_backend=cp.SCIPY_CANON_BACKEND,\n",
    "    solver=cp.SCS,\n",
    "    complexity=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sets up a convex optimization problem for a given number of qubits and multiplier.\n",
    "\n",
    "    Parameters:\n",
    "        block_qubits (int): The number of qubits in a block. Default is block_qubits_num.\n",
    "        multiplier (int): The size parameter for the bosonic basis. Default is t_factor.\n",
    "        Verbose (bool): If True, prints progress information. Default is False.\n",
    "        Antiid_dim_set (list): A list of dimensions for the anti-identity operations. Default is [6].\n",
    "        canon_backend: The canonicalization backend for cvxpy. Default is cp.SCIPY_CANON_BACKEND.\n",
    "        solver: The solver for cvxpy. Default is cp.SCS.\n",
    "        complexity (bool): If True, uses complex-valued variables. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        orbits (dict)\n",
    "        conversion_matrix (np.ndarray)\n",
    "        prob (cp.Problem)\n",
    "        reduced_embedded_matrix (cp.Parameter)\n",
    "        current_var (cp.Variable)\n",
    "        basis (list of tuples)\n",
    "        basis_dict (dict)\n",
    "    \"\"\"\n",
    "    block = 2**block_qubits\n",
    "\n",
    "    # Orbit counting:\n",
    "    orbits, _, basis, basis_dict, conversion_matrix = orbit_counting(\n",
    "        t_multiplier=multiplier, qubit_num=block_qubits, AnId_dim_set=Antiid_dim_set, verbose=Verbose\n",
    "    )\n",
    "\n",
    "    reduced_embedded_matrix = cp.Parameter((len(orbits), len(orbits)), hermitian=True)\n",
    "\n",
    "    if complexity:\n",
    "        current_var = cp.Variable((len(orbits), len(orbits)), hermitian=True)\n",
    "        constraints = [cp.trace(current_var) == 1, current_var >> 0]\n",
    "        objective = cp.real(cp.trace(reduced_embedded_matrix @ current_var))\n",
    "    else:\n",
    "        current_var = cp.Variable((len(orbits), len(orbits)), PSD=True)\n",
    "        constraints = [cp.trace(current_var) == 1]\n",
    "        # Avoid cp.real on a real expression in CVXPY\n",
    "        objective = cp.trace(reduced_embedded_matrix @ current_var)\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(objective), constraints)\n",
    "\n",
    "    return orbits, conversion_matrix, prob, reduced_embedded_matrix, current_var, basis, basis_dict\n",
    "\n",
    "\n",
    "def split_convex_run(\n",
    "    initstate,\n",
    "    conversion_matrix,\n",
    "    problemo,\n",
    "    parametero,\n",
    "    variableo,\n",
    "    block_qubits=block_qubits_num,\n",
    "    multiplier=t_factor,\n",
    "    Verbose=False,\n",
    "    canon_backend=cp.SCIPY_CANON_BACKEND,\n",
    "    solver=cp.SCS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a pre-setup convex optimization problem for a given initial matrix.\n",
    "\n",
    "    Parameters:\n",
    "        initstate (np.ndarray): The initial state vector.\n",
    "        conversion_matrix (np.ndarray): The conversion matrix for the basis transformation.\n",
    "        problemo (cp.Problem): The convex optimization problem.\n",
    "        parametero (cp.Parameter): The parameter for the reduced embedded matrix.\n",
    "        variableo (cp.Variable): The optimization variable.\n",
    "        block_qubits (int): The number of qubits in a block. Default is block_qubits_num.\n",
    "        multiplier (int): The size parameter for the bosonic basis. Default is t_factor.\n",
    "        Verbose (bool): If True, prints progress information. Default is False.\n",
    "        canon_backend: The canonicalization backend for cvxpy. Default is cp.SCIPY_CANON_BACKEND.\n",
    "        solver: The solver for cvxpy. Default is cp.SCS.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sol, var_value)\n",
    "    \"\"\"\n",
    "    block = 2**block_qubits\n",
    "    embedded_matrix = build_embedded_matrix(initstate, block_dim=block, size=multiplier)\n",
    "    reduced_embedded_matrix = reduce_embedded(embedded_matrix, conversion_matrix=conversion_matrix)\n",
    "    # enforce Hermitian (solver tolerances can introduce tiny skew-Hermitian parts)\n",
    "    reduced_embedded_matrix = 0.5 * (reduced_embedded_matrix + reduced_embedded_matrix.conj().T)\n",
    "    parametero.value = reduced_embedded_matrix\n",
    "    sol = problemo.solve(canon_backend=canon_backend, solver=solver, eps=1e-6, max_iters=20000, verbose=Verbose)\n",
    "\n",
    "    if Verbose:\n",
    "        print(f\"Optimal value: {sol}\")\n",
    "        print(f\"Trace of reduced embedded matrix: {np.trace(reduced_embedded_matrix)}\")\n",
    "\n",
    "    return sol, variableo.value\n",
    "\n",
    "\n",
    "def construct_reduced_density_2(reduced_post_orbital, conversion_matrix, basis, basis_dict, copies):\n",
    "    \"\"\"\n",
    "    Computes the reduced density matrix for one subsystem from the density matrix in the reduced basis.\n",
    "\n",
    "    Parameters:\n",
    "        rho_reduced (np.ndarray): The density matrix in the reduced basis.\n",
    "        conversion_matrix (np.ndarray): The conversion matrix from orbit counting.\n",
    "        basis (np.ndarray or list of tuples): Bosonic occupation number basis.\n",
    "        basis_dict : dictionary of basis states.\n",
    "        copies (int, >0): Number of copies, (i.e. numper of particles)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reduced density matrix for one subsystem.\n",
    "    \"\"\"\n",
    "    rho = conversion_matrix.conj().T @ reduced_post_orbital @ conversion_matrix\n",
    "    rho = 0.5 * (rho + rho.conj().T)\n",
    "\n",
    "    trace_rho = np.trace(rho)\n",
    "    if not np.isclose(trace_rho, 1.0):\n",
    "        raise ValueError(\"rho is not properly normalized. Trace is not 1.\")\n",
    "\n",
    "    dim_full = len(basis)\n",
    "    dim_reduced = len(basis[0])\n",
    "    rho_1 = np.zeros((dim_reduced, dim_reduced), dtype=complex)\n",
    "\n",
    "    # compute matrices of creation and anihilation operators:\n",
    "    a_i_dag_a_j = np.zeros((dim_reduced, dim_reduced, dim_full, dim_full))\n",
    "    for i in range(dim_reduced):\n",
    "        for j in range(dim_reduced):\n",
    "            for vector in basis:\n",
    "                new_vector, coeff = aidaj(i, j, vector)\n",
    "                a_i_dag_a_j[i][j][basis_dict[vector]][basis_dict[new_vector]] = coeff\n",
    "    # normalization\n",
    "    a_i_dag_a_j *= (1 / copies)\n",
    "\n",
    "    # computing 1-rdm\n",
    "    for i in range(dim_reduced):\n",
    "        for j in range(dim_reduced):\n",
    "            rho_1[i][j] = np.trace(rho @ a_i_dag_a_j[j][i])\n",
    "\n",
    "    trrho = np.trace(rho_1)\n",
    "    if not np.isclose(trrho, 1.0):\n",
    "        raise ValueError(\"rho_1 is not properly normalized. Trace is not 1.\")\n",
    "    return rho_1\n",
    "\n",
    "\n",
    "#just renaming\n",
    "def multinomial_coeff_int(a):\n",
    "    return multinomial_coeff(a)\n",
    "\n",
    "#use teh balls & bins logic to define functions faster\n",
    "def AnId_restrict_occup(obj, choose_idx):\n",
    "    # take occupancy vector -> restricted occupancy with ones at choose_idx\n",
    "    t = sum(obj); k = len(choose_idx)\n",
    "    res = [0] * len(obj)\n",
    "    # map positions 0..t-1 to bins of obj\n",
    "    pos = 0; ptr = 0\n",
    "    choose_idx = list(choose_idx)\n",
    "    for i, c in enumerate(obj):\n",
    "        end = pos + c\n",
    "        # count how many choose_idx fall in [pos,end)\n",
    "        while ptr < len(choose_idx) and choose_idx[ptr] < pos:\n",
    "            ptr += 1\n",
    "        c_here = 0\n",
    "        while ptr < len(choose_idx) and choose_idx[ptr] < end:\n",
    "            c_here += 1; ptr += 1\n",
    "        res[i] = c_here\n",
    "        pos = end\n",
    "    assert sum(res) == k\n",
    "    return tuple(res)\n",
    "\n",
    "def build_perm_maps(t_factor: int, block_qubits: int, AId_dim: int):\n",
    "    # one map per comb; each map is an array of length |basis|\n",
    "    block_dim = 2**block_qubits\n",
    "    basis, _tmp = global_basis_states(multipl=t_factor, block=block_dim, dictionary=True)\n",
    "    basis_dict = {v: i for i, v in enumerate(basis)}\n",
    "    N = len(basis)\n",
    "    refM, refV = reference_binary(block_size=block_qubits)\n",
    "    maps = []\n",
    "    for comb in combinations(range(t_factor), AId_dim):\n",
    "        out = np.empty(N, dtype=int)\n",
    "        for idx, v in enumerate(basis):\n",
    "            restr = AnId_restrict_occup(v, comb)\n",
    "            swapped = swapper(restr, reference=refM, reference_vec=refV)\n",
    "            new_v = tuple(np.array(v) - np.array(restr) + np.array(swapped))\n",
    "            out[idx] = basis_dict[new_v]\n",
    "        maps.append(out)\n",
    "    return maps, basis, basis_dict\n",
    "\n",
    "def compositions_k_into_d(k, d):\n",
    "    if d == 1:\n",
    "        return [(k,)]\n",
    "    out = []\n",
    "    def rec(prefix, rem, slots):\n",
    "        if slots == 1:\n",
    "            out.append(tuple(prefix + [rem])); return\n",
    "        for x in range(rem + 1):\n",
    "            rec(prefix + [x], rem - x, slots - 1)\n",
    "    rec([], k, d)\n",
    "    return out\n",
    "\n",
    "def build_perm_maps_compositions(t_factor: int, block_qubits: int, AId_dim: int):\n",
    "    block_dim = 2**block_qubits\n",
    "    basis, _tmp = global_basis_states(multipl=t_factor, block=block_dim, dictionary=True)\n",
    "    basis_dict = {v: i for i, v in enumerate(basis)}\n",
    "    N = len(basis)\n",
    "    refM, refV = reference_binary(block_size=block_qubits)\n",
    "\n",
    "    Rs = compositions_k_into_d(AId_dim, block_dim)  # count-vectors r s.t. sum r_i = AId_dim\n",
    "    maps = []\n",
    "    for r in Rs:\n",
    "        r = np.array(r, dtype=int)\n",
    "        # parity flip per Pauli label induced by r\n",
    "        swp = (refM.T @ r) % 2\n",
    "        perm = np.empty(block_dim, dtype=int)\n",
    "        for lbl, row in enumerate(refM):\n",
    "            out_bits = tuple((row + swp) % 2)\n",
    "            perm[lbl] = refV[out_bits]\n",
    "\n",
    "        out = np.arange(N, dtype=int)\n",
    "        for idx, v in enumerate(basis):\n",
    "            v = np.array(v, dtype=int)\n",
    "            if np.any(r > v):  # cannot choose this r\n",
    "                continue\n",
    "            swapped = np.zeros_like(v)\n",
    "            # move r[lbl] quanta from label lbl to perm[lbl]\n",
    "            for lbl, count in enumerate(r):\n",
    "                if count:\n",
    "                    swapped[perm[lbl]] += count\n",
    "            new_v = v - r + swapped\n",
    "            out[idx] = basis_dict[tuple(new_v)]\n",
    "        maps.append(out)\n",
    "    return maps, basis, basis_dict\n",
    "\n",
    "def orbit_counting_fast(t_factor: int,\n",
    "                        block_qubits: int,\n",
    "                        AId_dim_set=[6],\n",
    "                        verbose: bool=True,\n",
    "                        orbits_only: bool=False):\n",
    "    \"\"\"\n",
    "    Faster: no global map list. For each basis state, apply AId once per k and\n",
    "    union with all images returned by AnId_lesdim_1. Peak memory ~O(B), B=|basis|.\n",
    "    \"\"\"\n",
    "    d = 2**block_qubits\n",
    "    # bosonic basis and lookup\n",
    "    basis, basis_dict = global_basis_states(t_factor, d, dictionary=True)\n",
    "    refM, refV = reference_binary(block_size=block_qubits)\n",
    "    d = 2**block_qubits\n",
    "    basis, basis_dict = global_basis_states(t_factor, d, dictionary=True)\n",
    "    # make basis_dict point to indices, not zeros!!!!\n",
    "    for idx, b in enumerate(basis):\n",
    "        basis_dict[b] = idx\n",
    "\n",
    "    class DSU:\n",
    "        def __init__(self, n):\n",
    "            self.p = list(range(n)); self.r = [0]*n\n",
    "        def find(self, x):\n",
    "            while self.p[x] != x:\n",
    "                self.p[x] = self.p[self.p[x]]; x = self.p[x]\n",
    "            return x\n",
    "        def union(self, a, b):\n",
    "            ra, rb = self.find(a), self.find(b)\n",
    "            if ra == rb: return\n",
    "            if self.r[ra] < self.r[rb]: ra, rb = rb, ra\n",
    "            self.p[rb] = ra\n",
    "            if self.r[ra] == self.r[rb]: self.r[ra] += 1\n",
    "\n",
    "    N = len(basis)\n",
    "    dsu = DSU(N)\n",
    "\n",
    "    # streaming unions, no dense maps kept in memory\n",
    "    pb = tqdm(total=N*len(AId_dim_set),\n",
    "              desc=\"AId unions (streaming)\", unit=\"state\",\n",
    "              disable=not verbose,\n",
    "              bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\")\n",
    "    for k in AId_dim_set:\n",
    "        for i, occ in enumerate(basis):\n",
    "            # set of images produced by AId on size-k block placements\n",
    "            imgs = AnId_lesdim_1(occ, reference=refM, reference_vec=refV,\n",
    "                                 AId_dim=k, t_factor=t_factor)\n",
    "            # union i with each image index\n",
    "            for occ2 in imgs:\n",
    "                j = basis_dict[occ2]\n",
    "                dsu.union(i, j)\n",
    "            pb.update(1)\n",
    "    pb.close()\n",
    "\n",
    "    # components → orbit lists\n",
    "    comps = defaultdict(list)\n",
    "    for i in range(N):\n",
    "        comps[dsu.find(i)].append(i)\n",
    "\n",
    "    if orbits_only:\n",
    "        if verbose:\n",
    "            print(f\"orbits: {len(comps)}  basis: {N}\")\n",
    "        return comps, basis, basis_dict, None\n",
    "\n",
    "    # sparse conversion C with multinomial weights (orthonormal rows)\n",
    "    # precompute log-factorials once for fast multinomials\n",
    "    logfac = np.array([math.lgamma(k+1) for k in range(t_factor+1)], dtype=float)\n",
    "    def multinomial_fast(v):\n",
    "        s = logfac[t_factor]\n",
    "        for x in v: s -= logfac[x]\n",
    "        return math.exp(s)\n",
    "\n",
    "    R = len(comps); rows = []; cols = []; data = []\n",
    "    pb = tqdm(total=R, desc=\"Build C\", unit=\"orbit\",\n",
    "              disable=not verbose,\n",
    "              bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\")\n",
    "    for r, idxs in enumerate(comps.values()):\n",
    "        w = np.fromiter((multinomial_fast(basis[j]) for j in idxs), float)\n",
    "        w = np.sqrt(w / w.sum())\n",
    "        rows += [r]*len(idxs); cols += idxs; data += w.tolist()\n",
    "        pb.update(1)\n",
    "    pb.close()\n",
    "\n",
    "    C = csr_matrix((data, (rows, cols)), shape=(R, N))\n",
    "    if verbose:\n",
    "        print(f\"orbits: {R}  basis: {N}\")\n",
    "    return comps, basis, basis_dict, C\n",
    "\n",
    "def build_reduced_operator(H, C_csr, C_csc, basis, basis_dict, t_factor: int):\n",
    "    # H is (d x d). Implement (1/t) * sum_{ij} H_{ij} a_i^† a_j, projected as C A C^T.\n",
    "    R, _ = C_csr.shape\n",
    "    d = H.shape[0]\n",
    "    Hred = lil_matrix((R, R), dtype=complex if np.iscomplexobj(H) else float)\n",
    "\n",
    "    for k, v in enumerate(basis):\n",
    "        ck = C_csc.getcol(k)  # column of C for source\n",
    "        for j, vj in enumerate(v):\n",
    "            if vj == 0:\n",
    "                continue\n",
    "            sqrt_out = math.sqrt(vj)\n",
    "            v_base = list(v); v_base[j] -= 1\n",
    "            for i in range(d):\n",
    "                hij = H[i, j]\n",
    "                if hij == 0:\n",
    "                    continue\n",
    "                v_new = v_base.copy(); v_new[i] += 1\n",
    "                l = basis_dict[tuple(v_new)]\n",
    "                val = (hij * sqrt_out * math.sqrt(v_new[i])) / t_factor\n",
    "                cl = C_csc.getcol(l)  # column of C for target\n",
    "                Hred += val * (ck @ cl.T)\n",
    "    return Hred.tocsr()\n",
    "\n",
    "def precompute_Q(block_qubits: int, t_factor: int, C, basis, basis_dict):\n",
    "    d = 2**block_qubits\n",
    "    C_csr, C_csc = C.tocsr(), C.tocsc()\n",
    "    Q = {}\n",
    "    eye = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            E = eye.copy(); E[i, j] = 1.0\n",
    "            Q[(i, j)] = build_reduced_operator(E, C_csr, C_csc, basis, basis_dict, t_factor)\n",
    "    return Q\n",
    "\n",
    "def reduced_from_Q(H, Q):\n",
    "    d = H.shape[0]\n",
    "    out = None\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            hij = H[i, j]\n",
    "            if hij == 0:\n",
    "                continue\n",
    "            out = Q[(i, j)] * hij if out is None else out + Q[(i, j)] * hij\n",
    "    return out.tocsr()\n",
    "\n",
    "def setup_reduced_sdp(R: int, complex_var: bool):\n",
    "    if complex_var:\n",
    "        X = cp.Variable((R, R), hermitian=True)\n",
    "        Hpar = cp.Parameter((R, R), hermitian=True)\n",
    "        obj = cp.real(cp.trace(Hpar @ X))\n",
    "    else:\n",
    "        X = cp.Variable((R, R), symmetric=True)\n",
    "        Hpar = cp.Parameter((R, R))\n",
    "        obj = cp.trace(Hpar @ X)  # no cp.real on a real expression\n",
    "        # alternatively: obj = cp.sum(cp.multiply(Hpar, X))  # == trace(Hpar.T @ X)\n",
    "    prob = cp.Problem(cp.Maximize(obj), [cp.trace(X) == 1, X >> 0])\n",
    "    return prob, Hpar, X\n",
    "\n",
    "# build once per (n_qubits, t)\n",
    "def prepare_sweep_bases(M, Q):\n",
    "    Hr = {}\n",
    "    for key in (\"XX\", \"XZ\", \"ZI\", \"YY\", \"YZ\", \"ZY\"):  # compute what you need\n",
    "        if key in M:\n",
    "            Hr[key] = reduced_from_Q(M[key], Q).toarray()\n",
    "    return Hr\n",
    "\n",
    "def run_reduced(H, prob, Hpar, X, Q=None, C=None, basis=None, basis_dict=None, t_factor=None):\n",
    "    if Q is not None:\n",
    "        Hred = reduced_from_Q(H, Q)\n",
    "    else:\n",
    "        # fallback if Q not given\n",
    "        Hred = build_reduced_operator(H, C.tocsr(), C.tocsc(), basis, basis_dict, t_factor)\n",
    "    Hpar.value = Hred.toarray()\n",
    "    val = prob.solve(solver=cp.SCS, eps=1e-4, max_iters=10000, verbose=False)\n",
    "    return val, X.value\n",
    "\n",
    "def rdm1_from_reduced(rho_red, Q, t_factor):\n",
    "    # Q[(i,j)] already equals C (a_i^\\dag a_j / t) C^T\n",
    "    R = csr_matrix(rho_red)\n",
    "    d = max(i for i, _ in Q.keys()) + 1\n",
    "    rho1 = np.zeros((d, d), dtype=complex)\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            rho1[i, j] = (Q[(j, i)].multiply(R)).sum()   # no extra / t\n",
    "    return rho1\n",
    "\n",
    "def check_C_orthonormal(C, atol=1e-8):\n",
    "    I = (C @ C.T).toarray()\n",
    "    return np.allclose(I, np.eye(I.shape[0]), atol=atol)\n",
    "\n",
    "def check_objective_match(H, rho_red, C, basis, basis_dict, t_factor, Q, atol=1e-7):\n",
    "    # rebuild Hred via Q and compare Tr(Hred rho_red) against full lift\n",
    "    Hred = reduced_from_Q(H, Q)\n",
    "    lhs = float(np.real((Hred.multiply(csr_matrix(rho_red))).sum()))\n",
    "    # faster: reuse reduced build path\n",
    "    Hred2 = build_reduced_operator(H, C.tocsr(), C.tocsc(), basis, basis_dict, t_factor)\n",
    "    rhs = float(np.real((Hred2.multiply(csr_matrix(rho_red))).sum()))\n",
    "    return abs(lhs - rhs) <= atol\n",
    "\n",
    "def check_rdm_trace(rho1, atol=1e-8):\n",
    "    return abs(np.trace(rho1) - 1.0) <= atol\n",
    "\n",
    "def spectral_norm_preserved(H, Hred, atol=1e-7):\n",
    "    sH = np.linalg.svd(H, compute_uv=False)[0]\n",
    "    sR = np.linalg.svd(Hred.toarray(), compute_uv=False)[0]\n",
    "    return abs(sH - sR) <= atol\n",
    "\n",
    "\n",
    "# Magic assesment: trace gap + robustness (clean block)\n",
    "# =========================================\n",
    "\n",
    "\n",
    "# ---------- Pauli utilities ----------\n",
    "I = np.array([[1,0],[0,1]], dtype=complex)\n",
    "X = np.array([[0,1],[1,0]], dtype=complex)\n",
    "Y = np.array([[0,-1j],[1j,0]], dtype=complex)\n",
    "Z = np.array([[1,0],[0,-1]], dtype=complex)\n",
    "_ONEQ = {'I':I,'X':X,'Y':Y,'Z':Z}\n",
    "\n",
    "def _kron_all(mats):\n",
    "    out = np.array([[1]], dtype=complex)\n",
    "    for M in mats: out = np.kron(out, M)\n",
    "    return out\n",
    "\n",
    "def pauli_label_to_matrix(label):           # e.g. \"XIZ\"\n",
    "    return _kron_all([_ONEQ[c] for c in label])\n",
    "\n",
    "def all_pauli_labels(n):                    # includes all-I\n",
    "    return [''.join(p) for p in product('IXYZ', repeat=n)]\n",
    "\n",
    "def pauli_weight(label):                    # Hamming weight ignoring I\n",
    "    return sum(c!='I' for c in label)\n",
    "\n",
    "# ---------- Stabilizer enumeration (pure, n<=3, includes ± signs) ----------\n",
    "def _xz_from_label(label):\n",
    "    x = np.array([c in ('X','Y') for c in label], dtype=np.uint8)\n",
    "    z = np.array([c in ('Z','Y') for c in label], dtype=np.uint8)\n",
    "    return x, z\n",
    "\n",
    "def _symp_commutes(x1,z1,x2,z2):\n",
    "    return ((x1 & z2).sum() ^ (z1 & x2).sum()) % 2 == 0\n",
    "\n",
    "def _gf2_rank(A):\n",
    "    A = A.copy() % 2\n",
    "    m,n = A.shape\n",
    "    r = 0; c = 0\n",
    "    while r < m and c < n:\n",
    "        piv = None\n",
    "        for i in range(r,m):\n",
    "            if A[i,c]: piv = i; break\n",
    "        if piv is None: c += 1; continue\n",
    "        if piv != r: A[[r,piv]] = A[[piv,r]]\n",
    "        for i in range(m):\n",
    "            if i!=r and A[i,c]: A[i,:] ^= A[r,:]\n",
    "        r += 1; c += 1\n",
    "    return r\n",
    "\n",
    "def enumerate_pure_stabilizers(n):\n",
    "    assert n<=3, \"Enumeration provided for n<=3.\"\n",
    "    labels = all_pauli_labels(n)[1:]  # drop all-I\n",
    "    xz = [_xz_from_label(L) for L in labels]\n",
    "    paulis = [pauli_label_to_matrix(L) for L in labels]\n",
    "    N = 2**n\n",
    "    seen = {}\n",
    "    for idxs in combinations(range(len(labels)), n):\n",
    "        ok = True\n",
    "        for a,b in combinations(idxs,2):\n",
    "            if not _symp_commutes(*xz[a], *xz[b]): ok=False; break\n",
    "        if not ok: continue\n",
    "        M = np.vstack([np.concatenate(xz[i]) for i in idxs])\n",
    "        if _gf2_rank(M) != n: continue\n",
    "        for signs_bits in product([+1,-1], repeat=n):\n",
    "            rho = np.eye(N, dtype=complex)\n",
    "            for i, sgn in zip(idxs, signs_bits):\n",
    "                rho = rho @ (np.eye(N, dtype=complex) + sgn*paulis[i])\n",
    "            rho *= (1/(2**n))\n",
    "            rho = (rho + rho.conj().T)/2\n",
    "            key = (np.round(rho.real,12) + 1j*np.round(rho.imag,12)).tobytes()\n",
    "            seen[key] = rho\n",
    "    stabs = list(seen.values())\n",
    "    target = {1:6, 2:60, 3:1080}[n]\n",
    "    if len(stabs) != target:\n",
    "        print(f\"[warn] stabilizer count {len(stabs)} != {target}\")\n",
    "    return stabs\n",
    "\n",
    "# ---------- Operator utilities ----------\n",
    "def op_norm_inf(W):                         # spectral norm (Hermitian)\n",
    "    ev = np.linalg.eigvalsh((W + W.conj().T)/2)\n",
    "    return float(np.max(np.abs(ev)))\n",
    "\n",
    "def support_over_stabilizers(W, stabs):     # max Tr(W σ)\n",
    "    return float(np.max([np.real(np.trace(W @ s)) for s in stabs]))\n",
    "\n",
    "# ---------- Direction bank (deterministic + optional Bloch mesh + random) ----------\n",
    "_DBANK_CTX = {\"s_sym_oracle\": None, \"stabs\": None, \"tol\": 1e-6, \"max_tries\": 30, \"bloch_mesh\": None}\n",
    "\n",
    "def set_direction_bank_sanity(s_sym_oracle, stabs, tol=1e-6, max_tries=30):\n",
    "    _DBANK_CTX.update({\"s_sym_oracle\": s_sym_oracle, \"stabs\": stabs, \"tol\": tol, \"max_tries\": max_tries})\n",
    "\n",
    "def set_bloch_mesh(num_theta, num_phi):     # n=1 only; optional dense sweep\n",
    "    _DBANK_CTX[\"bloch_mesh\"] = (int(num_theta), int(num_phi))\n",
    "\n",
    "def _sanitize_W(W, make_traceless=True, normalize=True):\n",
    "    W = 0.5*(W + W.conj().T)\n",
    "    d = W.shape[0]\n",
    "    if make_traceless:\n",
    "        W = W - (np.trace(W)/d)*np.eye(d, dtype=complex)\n",
    "    if normalize:\n",
    "        ev = np.linalg.eigvalsh(W)\n",
    "        norm = float(np.max(np.abs(ev)))\n",
    "        if norm < 1e-12: return None\n",
    "        W = W / norm\n",
    "    return W\n",
    "\n",
    "def _random_pauli_combo(n, rng):\n",
    "    labels = all_pauli_labels(n)  # includes identity\n",
    "    coeff  = rng.normal(size=len(labels))\n",
    "    return sum(c*pauli_label_to_matrix(L) for c,L in zip(coeff, labels))\n",
    "\n",
    "def _pass_sanity(W):\n",
    "    s_sym_oracle = _DBANK_CTX[\"s_sym_oracle\"]\n",
    "    stabs        = _DBANK_CTX[\"stabs\"]\n",
    "    tol          = _DBANK_CTX[\"tol\"]\n",
    "    if s_sym_oracle is None or stabs is None:\n",
    "        return True\n",
    "    s_stb = support_over_stabilizers(W, stabs)\n",
    "    if s_stb > 1.0 + tol: return False\n",
    "    s_sym = float(s_sym_oracle(W))\n",
    "    return (s_sym <= 1.0 + tol)\n",
    "\n",
    "def _bloch_mesh_witnesses(num_theta=181, num_phi=361):  # n=1 only\n",
    "    thetas = np.linspace(0, np.pi, num_theta)\n",
    "    phis   = np.linspace(0, 2*np.pi, num_phi, endpoint=False)\n",
    "    Ws, Ns = [], []\n",
    "    for it, th in enumerate(thetas):\n",
    "        s = np.sin(th); c = np.cos(th)\n",
    "        for ip, ph in enumerate(phis):\n",
    "            nx = s*np.cos(ph); ny = s*np.sin(ph); nz = c\n",
    "            W  = nx*X + ny*Y + nz*Z   # op-norm=1\n",
    "            Ws.append(W); Ns.append(f\"BLOCH:th{it}:ph{ip}\")\n",
    "    return Ws, Ns\n",
    "\n",
    "def direction_bank(n, max_weight=2, include_collective=True, n_random=0, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    labels = all_pauli_labels(n)\n",
    "\n",
    "    # deterministic Pauli directions\n",
    "    pauli_dirs = [L for L in labels if L!='I'*n and 1 <= pauli_weight(L) <= max_weight]\n",
    "    W_list = [pauli_label_to_matrix(L) for L in pauli_dirs]\n",
    "    names  = [f\"P:{L}\" for L in pauli_dirs]\n",
    "\n",
    "    # collective sums\n",
    "    if include_collective:\n",
    "        sx = sum(pauli_label_to_matrix(''.join('X' if k==i else 'I' for k in range(n))) for i in range(n))\n",
    "        sz = sum(pauli_label_to_matrix(''.join('Z' if k==i else 'I' for k in range(n))) for i in range(n))\n",
    "        W_list += [sx, sz]; names += [\"COL:Sx\",\"COL:Sz\"]\n",
    "        if n>=2:\n",
    "            for i in range(n):\n",
    "                for j in range(i+1,n):\n",
    "                    lab_xx = ''.join('X' if k in (i,j) else 'I' for k in range(n))\n",
    "                    lab_zz = ''.join('Z' if k in (i,j) else 'I' for k in range(n))\n",
    "                    W_list += [pauli_label_to_matrix(lab_xx), pauli_label_to_matrix(lab_zz)]\n",
    "                    names  += [f\"COL:XX{i}{j}\", f\"COL:ZZ{i}{j}\"]\n",
    "\n",
    "    # structured 1-qubit witnesses\n",
    "    if n == 1:\n",
    "        for A, nm in [(X,'X'), (Y,'Y'), (Z,'Z')]:\n",
    "            for sgn in (+1,-1):\n",
    "                W = sgn*A\n",
    "                if _pass_sanity(W): W_list.append(W); names.append(f\"STR:axis:{'+' if sgn>0 else '-'}{nm}\")\n",
    "        for sx_s in (+1,-1):\n",
    "            for sz_s in (+1,-1):\n",
    "                W = (sx_s*X + sz_s*Z)/np.sqrt(2.0)\n",
    "                if _pass_sanity(W): W_list.append(W); names.append(f\"STR:diag2:{'+' if sx_s>0 else '-'}X{'+' if sz_s>0 else '-'}Z\")\n",
    "        for sx_s in (+1,-1):\n",
    "            for sy_s in (+1,-1):\n",
    "                for sz_s in (+1,-1):\n",
    "                    W = (sx_s*X + sy_s*Y + sz_s*Z)/np.sqrt(3.0)\n",
    "                    if _pass_sanity(W): W_list.append(W); names.append(\n",
    "                        f\"STR:diag3:{'+' if sx_s>0 else '-'}X{'+' if sy_s>0 else '-'}Y{'+' if sz_s>0 else '-'}Z\")\n",
    "    # --- structured 2-qubit witnesses (n==2) ---\n",
    "    if n == 2:\n",
    "        def _add(W, tag):\n",
    "            Wn = _sanitize_W(W, make_traceless=True, normalize=True)\n",
    "            if Wn is not None and _pass_sanity(Wn):\n",
    "                W_list.append(Wn); names.append(tag)\n",
    "\n",
    "        XX = np.kron(X, X); YY = np.kron(Y, Y); ZZ = np.kron(Z, Z)\n",
    "        XZ = np.kron(X, Z); ZX = np.kron(Z, X)\n",
    "\n",
    "        # Heisenberg-type: (±XX ± YY ± ZZ)/√3\n",
    "        for sx in (+1, -1):\n",
    "            for sy in (+1, -1):\n",
    "                for sz in (+1, -1):\n",
    "                    W = (sx*XX + sy*YY + sz*ZZ)/np.sqrt(3.0)\n",
    "                    _add(W, f\"STR2:Heis:{'+' if sx>0 else '-'}XX{'+' if sy>0 else '-'}YY{'+' if sz>0 else '-'}ZZ\")\n",
    "\n",
    "        # Anisotropic pairs: (±XX ± ZZ)/√2, (±XX ± YY)/√2, (±YY ± ZZ)/√2\n",
    "        for (A, An, B, Bn) in [\n",
    "            (XX, \"XX\", ZZ, \"ZZ\"),\n",
    "            (XX, \"XX\", YY, \"YY\"),\n",
    "            (YY, \"YY\", ZZ, \"ZZ\"),\n",
    "        ]:\n",
    "            for s1 in (+1, -1):\n",
    "                for s2 in (+1, -1):\n",
    "                    W = (s1*A + s2*B)/np.sqrt(2.0)\n",
    "                    _add(W, f\"STR2:pair:{'+' if s1>0 else '-'}{An}{'+' if s2>0 else '-'}{Bn}\")\n",
    "\n",
    "        # CHSH-type cores (balanced forms, then sanitized to ||W||∞=1)\n",
    "        bases = [\n",
    "            (XX + XZ + ZX - ZZ)/2.0,\n",
    "            (XX - XZ - ZX - ZZ)/2.0,\n",
    "            (-XX + XZ + ZX - ZZ)/2.0,\n",
    "            (XX + ZZ - XZ - ZX)/2.0,\n",
    "        ]\n",
    "        for i, B in enumerate(bases):\n",
    "            _add(B, f\"STR2:CHSH:{i}\")\n",
    "\n",
    "        # Bell-state projectors minus I/4 (traceless; then normalized)\n",
    "        e00 = np.array([1,0,0,0], dtype=complex)[:, None]\n",
    "        e01 = np.array([0,1,0,0], dtype=complex)[:, None]\n",
    "        e10 = np.array([0,0,1,0], dtype=complex)[:, None]\n",
    "        e11 = np.array([0,0,0,1], dtype=complex)[:, None]\n",
    "        phi_plus  = (e00 + e11)/np.sqrt(2.0)\n",
    "        phi_minus = (e00 - e11)/np.sqrt(2.0)\n",
    "        psi_plus  = (e01 + e10)/np.sqrt(2.0)\n",
    "        psi_minus = (e01 - e10)/np.sqrt(2.0)\n",
    "        for lab, v in [(\"Phi+\",phi_plus), (\"Phi-\",phi_minus), (\"Psi+\",psi_plus), (\"Psi-\",psi_minus)]:\n",
    "            P = v @ v.conj().T\n",
    "            W = P - 0.25*np.eye(4, dtype=complex)\n",
    "            _add(W, f\"STR2:Bell:{lab}\")\n",
    "            \n",
    "    # optional Bloch mesh (n=1)\n",
    "    bm = _DBANK_CTX.get(\"bloch_mesh\", None)\n",
    "    if n == 1 and bm is not None:\n",
    "        Wb, Nb = _bloch_mesh_witnesses(bm[0], bm[1])\n",
    "        for W, nm in zip(Wb, Nb):\n",
    "            if _pass_sanity(W): W_list.append(W); names.append(nm)\n",
    "\n",
    "    # random (screened)\n",
    "    if n_random>0:\n",
    "        kept = 0; tries = 0; max_tries_total = _DBANK_CTX[\"max_tries\"]*max(1,n_random)\n",
    "        while kept < n_random and tries < max_tries_total:\n",
    "            tries += 1\n",
    "            W0 = _random_pauli_combo(n, rng)\n",
    "            W  = _sanitize_W(W0, make_traceless=True, normalize=True)\n",
    "            if W is None: continue\n",
    "            if _pass_sanity(W):\n",
    "                names.append(f\"RND:{kept}\"); W_list.append(W); kept += 1\n",
    "\n",
    "    return W_list, names\n",
    "\n",
    "# ---------- Robustness lower bound  ----------\n",
    "def solve_dual_robustness_lb(rho1, stabs, solver=cp.SCS, eps=1e-6, max_iters=20000, verbose=False):\n",
    "    d = rho1.shape[0]\n",
    "    Z = cp.Variable((d,d), hermitian=True)\n",
    "    cons = [Z >> 0]\n",
    "    for s in stabs:\n",
    "        cons.append(cp.real(cp.trace(Z @ s)) <= 1)\n",
    "    obj = cp.Maximize(cp.real(cp.trace(Z @ rho1)) - 1)\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    val = prob.solve(solver=solver, eps=eps, max_iters=max_iters, verbose=verbose)\n",
    "    if val is None or not np.isfinite(val): return 0.0\n",
    "    return max(0.0, float(val))\n",
    "\n",
    "# ---------- Oracle wrapper SDP ----------\n",
    "def make_s_sym_oracle(n, t, Antiid_dim_set=[6], Verbose=False,\n",
    "                      canon_backend=cp.SCIPY_CANON_BACKEND, solver=cp.SCS):\n",
    "    setup = split_convex_setup(n, t, Verbose, Antiid_dim_set, canon_backend, solver, complexity=True)\n",
    "    conversion_matrix, problemo, parametero, variableo = setup[1], setup[2], setup[3], setup[4]\n",
    "    def s_sym_oracle(W):\n",
    "        val, _ = split_convex_run(W, conversion_matrix, problemo, parametero, variableo,\n",
    "                                  block_qubits=n, multiplier=t, Verbose=False,\n",
    "                                  canon_backend=canon_backend, solver=solver)\n",
    "        return float(val)\n",
    "    return s_sym_oracle, setup\n",
    "\n",
    "# ---------- Main driver ----------\n",
    "def compute_bounds_with_dual(n, t,\n",
    "                             Antiid_dim_set=[6],\n",
    "                             max_weight=2, include_collective=True,\n",
    "                             n_random=0, seed=0,\n",
    "                             solver_sdp=cp.SCS, verbose=False):\n",
    "    # prepare SDP and stabilizers\n",
    "    s_sym_oracle, setup = make_s_sym_oracle(n, t, Antiid_dim_set, verbose, cp.SCIPY_CANON_BACKEND, solver_sdp)\n",
    "    convC, problemo, paramH, varR = setup[1], setup[2], setup[3], setup[4]\n",
    "    basis, basis_dict = setup[5], setup[6]\n",
    "    stabs = enumerate_pure_stabilizers(n)\n",
    "\n",
    "    # register sanity for direction_bank randoms and optional Bloch mesh\n",
    "    set_direction_bank_sanity(lambda W: float(split_convex_run(W, convC, problemo, paramH, varR,\n",
    "                                                               block_qubits=n, multiplier=t, Verbose=False,\n",
    "                                                               canon_backend=cp.SCIPY_CANON_BACKEND,\n",
    "                                                               solver=solver_sdp)[0]),\n",
    "                              stabs, tol=1e-6, max_tries=30)\n",
    "\n",
    "    # directions\n",
    "    W_list, names = direction_bank(n, max_weight, include_collective, n_random, seed)\n",
    "\n",
    "    # per-direction metrics\n",
    "    rows = []\n",
    "    for name, W in zip(names, W_list):\n",
    "        s_sym_val, rho_red = split_convex_run(W, convC, problemo, paramH, varR,\n",
    "                                              block_qubits=n, multiplier=t, Verbose=False,\n",
    "                                              canon_backend=cp.SCIPY_CANON_BACKEND, solver=solver_sdp)\n",
    "        rho1 = construct_reduced_density_2(rho_red, convC, basis, basis_dict, t)  # 1-RDM\n",
    "\n",
    "        normW = op_norm_inf(W)\n",
    "        s_stb = support_over_stabilizers(W, stabs)\n",
    "        trace_bound = max(0.0, (s_sym_val - s_stb) / (2.0 * normW)) if normW>0 else 0.0\n",
    "        robust_lb   = solve_dual_robustness_lb(rho1, stabs, solver=solver_sdp, eps=1e-6, max_iters=20000, verbose=False)\n",
    "\n",
    "        rows.append({\n",
    "            \"n\": n, \"t\": t, \"direction\": name,\n",
    "            \"s_sym\": float(s_sym_val), \"s_stab\": float(s_stb), \"op_norm\": float(normW),\n",
    "            \"trace_bound\": float(trace_bound), \"robust_lb\": float(robust_lb)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"trace_bound\",\"robust_lb\"], ascending=False).reset_index(drop=True)\n",
    "    summary = {\n",
    "        \"n\": n, \"t\": t, \"num_dirs\": int(len(df)),\n",
    "        \"max_trace_bound\": float(df[\"trace_bound\"].max()) if len(df) else 0.0,\n",
    "        \"max_robust_lb\": float(df[\"robust_lb\"].max()) if len(df) else 0.0\n",
    "    }\n",
    "    return df, summary\n",
    "\n",
    "# ---------- Example (n=1, t=6) ----------\n",
    "# set_bloch_mesh(181, 361)  # optional dense sweep for n=1\n",
    "# df, summary = compute_bounds_with_dual(1, 6, Antiid_dim_set=[6], max_weight=1, include_collective=True,\n",
    "#                                        n_random=0, seed=123, solver_sdp=cp.SCS, verbose=True)\n",
    "# print(\"Summary:\", summary)\n",
    "# print(df.head(10).to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a692633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Metrics evaluation: LB_tr and LB_rob over a direction bank =====\n",
    "# Requirements assumed present in the notebook:\n",
    "# - Pauli/matrix defs: X, Y, Z, I, M dict\n",
    "# - Functions: split_convex_setup, split_convex_run, construct_reduced_density_2\n",
    "# - Anti-identity fixed to [6]\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from collections import Counter\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def op_norm_inf(A):\n",
    "    # spectral norm (largest singular value); Hermitian -> |largest eigenvalue|\n",
    "    return float(np.linalg.norm(A, 2))\n",
    "\n",
    "def normalize_op(A):\n",
    "    nrm = op_norm_inf(A)\n",
    "    return A / nrm if nrm > 0 else A\n",
    "\n",
    "def kron_n(ops):\n",
    "    out = np.array([[1.0]], dtype=complex)\n",
    "    for O in ops:\n",
    "        out = np.kron(out, O)\n",
    "    return out\n",
    "\n",
    "def one_qubit_stab_set():\n",
    "    # Six Pauli eigenstate projectors on Bloch axes\n",
    "    vecs = []\n",
    "    vecs += [np.array([1,1])/np.sqrt(2), np.array([1,-1])/np.sqrt(2)]          # ±X\n",
    "    vecs += [np.array([1,1j])/np.sqrt(2), np.array([1,-1j])/np.sqrt(2)]        # ±Y\n",
    "    vecs += [np.array([1,0]), np.array([0,1])]                                  # ±Z\n",
    "    return [np.outer(v, v.conj()) for v in vecs]\n",
    "\n",
    "# --- local-operator detection: W == A ⊗ I_rest ---\n",
    "def partial_trace_keep(W, n, keep):\n",
    "    \"\"\"\n",
    "    Trace out all but subsystem 'keep' (0-based). Qubits only. Returns 2x2.\n",
    "    \"\"\"\n",
    "    W = np.asarray(W, dtype=complex)\n",
    "    Wt = W.reshape([2]* (2*n))  # indices: (i0..i_{n-1}; j0..j_{n-1})\n",
    "    axes_all = list(range(2*n))\n",
    "    keep_axes = [keep, n+keep]\n",
    "    perm = keep_axes + [a for a in axes_all if a not in keep_axes]\n",
    "    Wp = np.transpose(Wt, axes=perm).reshape(2, 2, -1)\n",
    "    # sum over the remaining dimensions\n",
    "    return np.tensordot(Wp, np.ones(Wp.shape[2]), axes=([2],[0]))\n",
    "\n",
    "def is_local_kronI(W, n, tol=1e-9):\n",
    "    \"\"\"\n",
    "    Check if W == A ⊗ I_rest for some qubit. If yes return (True, j, A).\n",
    "    \"\"\"\n",
    "    W = np.asarray(W, dtype=complex).reshape(2**n, 2**n)\n",
    "    I2 = np.eye(2, dtype=complex)\n",
    "    for j in range(n):\n",
    "        Aj = partial_trace_keep(W, n, keep=j) / (2**(n-1))  # recover local part\n",
    "        ops = [I2]*n; ops[j] = Aj\n",
    "        if np.allclose(W, kron_n(ops), atol=tol):\n",
    "            return True, j, Aj\n",
    "    return False, None, None\n",
    "\n",
    "# ---- exact s_Stab for n=2 via full 2-qubit stabilizer set ----\n",
    "def _phase_fix(U):\n",
    "    # remove global phase so det≈1\n",
    "    det = np.linalg.det(U)\n",
    "    if det == 0:\n",
    "        return U\n",
    "    ph = np.exp(-0.5j * np.angle(det))\n",
    "    return ph * U\n",
    "\n",
    "@lru_cache(None)\n",
    "def clifford1_group():\n",
    "    # generate 1-qubit Clifford group from H and S\n",
    "    H = np.array([[1,1],[1,-1]], dtype=complex)/np.sqrt(2)\n",
    "    S = np.array([[1,0],[0,1j]], dtype=complex)\n",
    "    gens = [H, S]\n",
    "    G = [np.eye(2, dtype=complex)]\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for A in list(G):\n",
    "            for B in gens:\n",
    "                C = _phase_fix(A @ B)\n",
    "                if not any(np.allclose(C, X, atol=1e-12) for X in G):\n",
    "                    G.append(C); changed = True\n",
    "    return G  # size 24\n",
    "\n",
    "@lru_cache(None)\n",
    "def two_qubit_stab_set():\n",
    "    # All 2q stabilizer pure states = product stabilizers (36) + local-Clifford orbit of |Φ+> (24)\n",
    "    S1 = one_qubit_stab_set()\n",
    "    prod = [np.kron(A, B) for A in S1 for B in S1]\n",
    "\n",
    "    # Bell |Φ+>\n",
    "    v = np.zeros(4, dtype=complex); v[0] = 1/np.sqrt(2); v[3] = 1/np.sqrt(2)\n",
    "    bell = np.outer(v, v.conj())\n",
    "    ent = []\n",
    "    for U in clifford1_group():\n",
    "        for V in clifford1_group():\n",
    "            U2 = np.kron(U, V)\n",
    "            ent.append(U2 @ bell @ U2.conj().T)\n",
    "\n",
    "    # dedupe (Frobenius)\n",
    "    uniq = []\n",
    "    for M in prod + ent:\n",
    "        if not any(np.linalg.norm(M - N, 'fro') < 1e-10 for N in uniq):\n",
    "            uniq.append(M)\n",
    "    return uniq  # ~60\n",
    "\n",
    "def s_stab_support(W, n):\n",
    "    \"\"\"\n",
    "    s_Stab(W) = max_{sigma in Stab_n} Tr(W sigma).\n",
    "    - If W is local (A⊗I_rest), compute from 1q stabilizers exactly.\n",
    "    - Else if n==1 or n==2, compute exactly by enumeration.\n",
    "    - Else fallback to 1.0 (keeps bound valid but may be loose).\n",
    "    \"\"\"\n",
    "    W = np.asarray(W, dtype=complex)\n",
    "    ok, j, A = is_local_kronI(W, n, tol=1e-9)\n",
    "    if ok:\n",
    "        return max(float(np.real(np.trace(A @ S1))) for S1 in one_qubit_stab_set())\n",
    "    if n == 1:\n",
    "        return max(float(np.real(np.trace(W @ S))) for S in one_qubit_stab_set())\n",
    "    if n == 2:\n",
    "        return max(float(np.real(np.trace(W @ S))) for S in two_qubit_stab_set())\n",
    "    return 1.0  # conservative\n",
    "\n",
    "def robustness_dual_lb_on_1rdm(rho1, n):\n",
    "    \"\"\"\n",
    "    Lower bound on generalized robustness using the dual on the 1-RDM.\n",
    "    Exact for n=1 by constraining against all 1q stabilizers.\n",
    "    For n>=2, returns NaN unless extended with full stabilizer constraints.\n",
    "    \"\"\"\n",
    "    if n != 1:\n",
    "        return np.nan\n",
    "    S_set = one_qubit_stab_set()\n",
    "    Z = cp.Variable((2, 2), hermitian=True)\n",
    "    constraints = [Z >> 0] + [cp.real(cp.trace(Z @ S)) <= 1 for S in S_set]\n",
    "    prob = cp.Problem(cp.Maximize(cp.real(cp.trace(Z @ rho1)) - 1), constraints)\n",
    "    val = prob.solve(solver=cp.SCS, verbose=False)\n",
    "    return float(val)\n",
    "\n",
    "def clamp_support_value(val, eps=1e-8):\n",
    "    # clip tiny numerical overshoots above the norm cap 1\n",
    "    return min(float(np.real(val)), 1.0 + eps)\n",
    "\n",
    "# ---------- Direction banks ----------\n",
    "def build_structured_bank(n, include_collective=True):\n",
    "    \"\"\"\n",
    "    Structured single-copy witnesses, normalized to ||·||_inf = 1.\n",
    "    - Local axes on each qubit: X_j, Y_j, Z_j\n",
    "    - (X±Z)/√2 and (X±Y±Z)/√3 on each qubit\n",
    "    - Optional collective weight-1 sums: ΣX, ΣY, ΣZ\n",
    "    \"\"\"\n",
    "    bank = []\n",
    "\n",
    "    # single-axis per qubit\n",
    "    for j in range(n):\n",
    "        for lab, P in [('X', X), ('Y', Y), ('Z', Z)]:\n",
    "            ops = [I]*n; ops[j] = P\n",
    "            bank.append((f'{lab}{j+1}', normalize_op(kron_n(ops))))\n",
    "\n",
    "    # (X ± Z)/√2 and (X ± Y ± Z)/√3 per qubit\n",
    "    for j in range(n):\n",
    "        for s in (+1, -1):\n",
    "            opsX = [I]*n; opsX[j] = X\n",
    "            opsZ = [I]*n; opsZ[j] = Z\n",
    "            bank.append((f'({\"+-\"[s<0]}XZ){j+1}/√2', normalize_op((kron_n(opsX)+s*kron_n(opsZ))/np.sqrt(2))))\n",
    "        for sx in (+1, -1):\n",
    "            for sy in (+1, -1):\n",
    "                for sz in (+1, -1):\n",
    "                    ops = [I]*n\n",
    "                    ops[j] = sx*X  # sign is absorbed into the sum below\n",
    "                    W = (sx*kron_n([X if k==j else I for k in range(n)]) +\n",
    "                         sy*kron_n([Y if k==j else I for k in range(n)]) +\n",
    "                         sz*kron_n([Z if k==j else I for k in range(n)]))/np.sqrt(3)\n",
    "                    bank.append((f'({\"+-\"[sx<0]}X{\"+-\"[sy<0]}Y{\"+-\"[sz<0]}Z){j+1}/√3', normalize_op(W)))\n",
    "\n",
    "    # collective sums\n",
    "    if include_collective:\n",
    "        WsumX = sum(kron_n([X if k==j else I for j in range(n)]) for k in range(n))\n",
    "        WsumY = sum(kron_n([Y if k==j else I for j in range(n)]) for k in range(n))\n",
    "        WsumZ = sum(kron_n([Z if k==j else I for j in range(n)]) for k in range(n))\n",
    "        bank += [('ΣX', normalize_op(WsumX)),\n",
    "                 ('ΣY', normalize_op(WsumY)),\n",
    "                 ('ΣZ', normalize_op(WsumZ))]\n",
    "    return bank\n",
    "\n",
    "def build_random_bank(n, k=64, seed=0, screen=True):\n",
    "    \"\"\"\n",
    "    Random Hermitian directions, normalized. Optional blue-noise screening by farthest-point sampling (Frobenius).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    d = 2**n\n",
    "    mats = []\n",
    "    for i in range(k):\n",
    "        A = rng.standard_normal((d,d)) + 1j*rng.standard_normal((d,d))\n",
    "        H = (A + A.conj().T)/2\n",
    "        mats.append((f'RND:{i}', normalize_op(H)))\n",
    "\n",
    "    if not screen or k <= 8:\n",
    "        return mats\n",
    "\n",
    "    kept = [mats[0]]\n",
    "    remaining = mats[1:]\n",
    "    def frob_dist(A, B): return np.linalg.norm(A-B, 'fro')\n",
    "    target = min(k//2, 128)\n",
    "    while len(kept) < target and remaining:\n",
    "        best, best_sc = None, -1.0\n",
    "        for item in remaining:\n",
    "            _, W_i = item\n",
    "            mind = min(frob_dist(W_i, W_j) for _, W_j in kept)\n",
    "            if mind > best_sc:\n",
    "                best_sc = mind; best = item\n",
    "        kept.append(best); remaining.remove(best)\n",
    "    return kept\n",
    "\n",
    "def build_direction_bank(n, n_random=64, seed=0, include_collective=True):\n",
    "    bank = build_structured_bank(n, include_collective=include_collective)\n",
    "    bank += build_random_bank(n, k=n_random, seed=seed, screen=True)\n",
    "    # unique by name\n",
    "    seen, out = set(), []\n",
    "    for name, W in bank:\n",
    "        if name in seen: continue\n",
    "        seen.add(name); out.append((name, W))\n",
    "    return out\n",
    "# ---------- Robustness LBs (exact n=1,2; pairwise LB for n>=3) ----------\n",
    "\n",
    "def pt_keep_qubits(rho, n, keep):\n",
    "    \"\"\"\n",
    "    Partial trace to the qubits in 'keep' (iterable of 0-based indices).\n",
    "    Qubits only. Returns 2^{|keep|} x 2^{|keep|}.\n",
    "    \"\"\"\n",
    "    keep = sorted(keep)\n",
    "    rho = np.asarray(rho, dtype=complex).reshape([2] * (2*n))  # (i0..i_{n-1}; j0..j_{n-1})\n",
    "    # permutation: kept i, kept j, then all traced-out i, then traced-out j\n",
    "    kept_i = keep\n",
    "    kept_j = [n+k for k in keep]\n",
    "    rest  = [k for k in range(n) if k not in keep]\n",
    "    rest_i = rest\n",
    "    rest_j = [n+k for k in rest]\n",
    "    perm = kept_i + kept_j + rest_i + rest_j\n",
    "    R = np.transpose(rho, axes=perm)\n",
    "    d_keep = 2**len(keep)\n",
    "    R = R.reshape(d_keep, d_keep, 2**len(rest), 2**len(rest))\n",
    "    # trace over the last two blocks\n",
    "    return np.einsum('abcc->ab', R)\n",
    "\n",
    "def robustness_dual_lb_on_block(rho_block, n_block):\n",
    "    \"\"\"\n",
    "    Generalized robustness dual LB on an n_block-qubit density matrix.\n",
    "    Exact for n_block=1 (6 constraints) and n_block=2 (~60 constraints).\n",
    "    Returns NaN for n_block>=3 (use pairwise helper below).\n",
    "    \"\"\"\n",
    "    d = 2**n_block\n",
    "    if n_block == 1:\n",
    "        S_set = one_qubit_stab_set()\n",
    "    elif n_block == 2:\n",
    "        S_set = two_qubit_stab_set()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "    Z = cp.Variable((d, d), hermitian=True)\n",
    "    constraints = [Z >> 0] + [cp.real(cp.trace(Z @ S)) <= 1 for S in S_set]\n",
    "    prob = cp.Problem(cp.Maximize(cp.real(cp.trace(Z @ rho_block)) - 1), constraints)\n",
    "    val = prob.solve(solver=cp.SCS, verbose=False)\n",
    "    return float(val)\n",
    "\n",
    "def robustness_dual_lb_pairwise(rho_block, n_block):\n",
    "    \"\"\"\n",
    "    Valid LB for any n_block>=2: take max over all 2-qubit marginals.\n",
    "    Uses the exact 2-qubit dual on each pair (constraints vs Stab_2).\n",
    "    \"\"\"\n",
    "    if n_block < 2:\n",
    "        return robustness_dual_lb_on_block(rho_block, n_block)\n",
    "    from itertools import combinations\n",
    "    lbs = []\n",
    "    for (a,b) in combinations(range(n_block), 2):\n",
    "        rho2 = pt_keep_qubits(rho_block, n_block, keep=(a,b))\n",
    "        lbs.append(robustness_dual_lb_on_block(rho2, 2))\n",
    "    return float(np.nanmax(lbs)) if lbs else np.nan\n",
    "\n",
    "# ---------- Core evaluation ----------\n",
    "def evaluate_metrics(n_list, t_grid, n_random=64, seed=0, include_collective=True,\n",
    "                     solver_sdp=cp.SCS, verbose=False):\n",
    "    \"\"\"\n",
    "    For each n in n_list and t in t_grid[n], compute:\n",
    "      - s_sym(W), s_Stab(W), LB_tr per W\n",
    "      - rho^(1) and LB_rob (n=1 only, exact dual)\n",
    "      - maxima over W and winning direction names\n",
    "    Returns:\n",
    "      results: list of dict rows per (n,t,W)\n",
    "      summary: list of dict rows per (n,t)\n",
    "    \"\"\"\n",
    "    all_rows, summaries = [], [] \n",
    "    for n in n_list:\n",
    "        bank = build_direction_bank(n, n_random=n_random, seed=seed, include_collective=include_collective)\n",
    "        for t in t_grid.get(n, []):\n",
    "            orbits, C, prob, Hpar, Xvar, basis, basis_dict = split_convex_setup(\n",
    "                block_qubits=n, multiplier=t, Verbose=verbose, Antiid_dim_set=[6], complexity=True\n",
    "            )\n",
    "            per_dir = []\n",
    "            pbar = tqdm(total=len(bank), desc=f\"n={n}, t={t} dirs\")\n",
    "            for name, W in bank:\n",
    "                W = normalize_op(W)\n",
    "                sol, rho_r = split_convex_run(\n",
    "                    initstate=W,\n",
    "                    conversion_matrix=C,\n",
    "                    problemo=prob,\n",
    "                    parametero=Hpar,\n",
    "                    variableo=Xvar,\n",
    "                    block_qubits=n,\n",
    "                    multiplier=t,\n",
    "                    Verbose=False,\n",
    "                    solver=solver_sdp\n",
    "                )\n",
    "                s_sym = clamp_support_value(sol, eps=1e-8)\n",
    "                rho1  = construct_reduced_density_2(rho_r, C, basis, basis_dict, copies=t)\n",
    "                \n",
    "                s_stab = s_stab_support(W, n)\n",
    "                gap    = max(0.0, s_sym - s_stab)\n",
    "                lb_tr  = 0.5 * gap\n",
    "                lb_rob_exact = robustness_dual_lb_on_block(rho1, n)\n",
    "                lb_rob = lb_rob_exact if not np.isnan(lb_rob_exact) else robustness_dual_lb_pairwise(rho1, n)\n",
    "\n",
    "                row = {'n': n, 't': t, 'direction': name,\n",
    "                       's_sym': s_sym, 's_stab': s_stab,\n",
    "                       'trace_bound': lb_tr, 'robust_lb': lb_rob}\n",
    "                per_dir.append(row); all_rows.append(row)\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "\n",
    "            best_tr  = max(per_dir, key=lambda r: r['trace_bound'])\n",
    "            rob_rows = [r for r in per_dir if not np.isnan(r['robust_lb'])]\n",
    "            best_rob = max(rob_rows, key=lambda r: r['robust_lb']) if rob_rows else {'robust_lb': np.nan, 'direction': None}\n",
    "\n",
    "            summaries.append({'n': n, 't': t, 'R': len(orbits),\n",
    "                              'LB_tr': best_tr['trace_bound'], 'dir_tr': best_tr['direction'],\n",
    "                              'LB_rob': best_rob['robust_lb'], 'dir_rob': best_rob.get('direction', None),\n",
    "                              'num_dirs': len(bank)})\n",
    "    return all_rows, summaries\n",
    "\n",
    "# ---------- Example usage ----------\n",
    "# n_list = [1,2,3]\n",
    "# t_grid = {1:[6,12,18], 2:[6,9,12], 3:[6,9]}\n",
    "# rows, summaries = evaluate_metrics(n_list, t_grid, n_random=64, seed=123, include_collective=True, verbose=False)\n",
    "# import pandas as pd; pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fa034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n=1, t=6 dirs: 100%|██████████| 66/66 [00:04<00:00, 16.09it/s]\n",
      "n=1, t=7 dirs: 100%|██████████| 66/66 [00:03<00:00, 21.55it/s]\n",
      "n=1, t=8 dirs: 100%|██████████| 66/66 [00:03<00:00, 16.78it/s]\n",
      "n=1, t=9 dirs: 100%|██████████| 66/66 [00:03<00:00, 20.66it/s]\n",
      "n=1, t=10 dirs: 100%|██████████| 66/66 [00:02<00:00, 24.67it/s]\n",
      "n=1, t=11 dirs: 100%|██████████| 66/66 [00:03<00:00, 21.31it/s]\n",
      "n=1, t=12 dirs: 100%|██████████| 66/66 [00:03<00:00, 19.15it/s]\n",
      "n=1, t=13 dirs: 100%|██████████| 66/66 [00:02<00:00, 24.03it/s]\n",
      "n=1, t=14 dirs: 100%|██████████| 66/66 [00:02<00:00, 23.36it/s]\n",
      "n=1, t=15 dirs: 100%|██████████| 66/66 [00:02<00:00, 23.92it/s]\n",
      "n=1, t=16 dirs: 100%|██████████| 66/66 [00:02<00:00, 26.07it/s]\n",
      "n=1, t=17 dirs: 100%|██████████| 66/66 [00:02<00:00, 23.84it/s]\n",
      "n=1, t=18 dirs: 100%|██████████| 66/66 [00:02<00:00, 23.85it/s]\n",
      "n=2, t=6 dirs: 100%|██████████| 79/79 [04:21<00:00,  3.32s/it]\n",
      "n=2, t=7 dirs: 100%|██████████| 79/79 [04:39<00:00,  3.54s/it]\n",
      "n=2, t=8 dirs: 100%|██████████| 79/79 [04:26<00:00,  3.38s/it]\n",
      "n=2, t=9 dirs: 100%|██████████| 79/79 [04:01<00:00,  3.06s/it]\n",
      "n=2, t=10 dirs: 100%|██████████| 79/79 [04:33<00:00,  3.46s/it]\n",
      "n=2, t=11 dirs: 100%|██████████| 79/79 [04:14<00:00,  3.22s/it]\n",
      "n=2, t=12 dirs: 100%|██████████| 79/79 [05:59<00:00,  4.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# ---------- Practical use ----------\n",
    "n_list = [1,2]\n",
    "t_grid = {1:[6,7,8,9,10,11,12,13,14,15,16,17,18], 2:[6,7,8,9,10,11,12]}\n",
    "rows, summaries = evaluate_metrics(n_list, t_grid, n_random=100, seed=123, include_collective=True, verbose=False)\n",
    "S=pd.DataFrame(summaries)\n",
    "R=pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3eb67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: lbtr_vs_t_n*_offsetfit.pdf, fit_params_offset_model.csv\n"
     ]
    }
   ],
   "source": [
    "# === LB_tr vs t with offset fit: y(t) ≈ c / sqrt(t - a) (no histograms, no orbit counts) ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"pdf.fonttype\": 42, \"ps.fonttype\": 42})\n",
    "\n",
    "# ---------- Load summaries ----------\n",
    "# Expected columns: n, t, LB_tr  (others are ignored here)\n",
    "try:\n",
    "    S = pd.read_csv(\"summary_per_nt.csv\")\n",
    "except FileNotFoundError:\n",
    "    S = pd.read_csv(\"thesis_summary_with_B.csv\")\n",
    "\n",
    "S = S.loc[:, [\"n\",\"t\",\"LB_tr\"]].dropna().copy()\n",
    "S[\"n\"] = S[\"n\"].astype(int)\n",
    "S[\"t\"] = S[\"t\"].astype(float)\n",
    "S[\"LB_tr\"] = S[\"LB_tr\"].astype(float)\n",
    "\n",
    "# ---------- Fitting y ≈ c / sqrt(t - a) ----------\n",
    "def _fit_c_given_a(t, y, a):\n",
    "    \"\"\"Analytic least-squares for c when a is fixed.\"\"\"\n",
    "    x = 1.0 / np.sqrt(t - a)\n",
    "    # guard against numerical issues\n",
    "    if not np.all(np.isfinite(x)):\n",
    "        return np.nan, np.nan, np.nan\n",
    "    denom = float(x @ x)\n",
    "    if denom <= 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    c = float((x @ y) / denom)\n",
    "    yhat = c * x\n",
    "    sse = float(np.sum((y - yhat)**2))\n",
    "    return c, yhat, sse\n",
    "\n",
    "def _golden_section(f, lo, hi, tol=1e-6, maxit=200):\n",
    "    \"\"\"Minimize f over [lo, hi] with golden-section search.\"\"\"\n",
    "    phi = (1 + 5**0.5) / 2\n",
    "    invphi = 1 / phi\n",
    "    invphi2 = (3 - 5**0.5) / 2\n",
    "    a, b = lo, hi\n",
    "    h = b - a\n",
    "    if h <= tol:\n",
    "        return (a + b) / 2\n",
    "    n = int(np.ceil(np.log(tol / h) / np.log(invphi)))\n",
    "    c = a + invphi2 * h\n",
    "    d = a + invphi * h\n",
    "    yc = f(c); yd = f(d)\n",
    "    for _ in range(min(maxit, n)):\n",
    "        if yc < yd:\n",
    "            b, d, yd = d, c, yc\n",
    "            h = b - a\n",
    "            c = a + invphi2 * h\n",
    "            yc = f(c)\n",
    "        else:\n",
    "            a, c, yc = c, d, yd\n",
    "            h = b - a\n",
    "            d = a + invphi * h\n",
    "            yd = f(d)\n",
    "    return (a + b) / 2\n",
    "\n",
    "def fit_offset_c_over_sqrt_t(t, y, a_min=None, a_max=None):\n",
    "    \"\"\"\n",
    "    Fit y ≈ c / sqrt(t - a). Returns (c, a, yfit, R2).\n",
    "    a is constrained to (a_min, a_max), with a_max < min(t).\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, float); y = np.asarray(y, float)\n",
    "    tmin = float(np.min(t))\n",
    "    # Bounds for a: by default search in [0, 0.9*tmin]\n",
    "    if a_max is None:\n",
    "        a_max = 0.9 * tmin\n",
    "    else:\n",
    "        a_max = min(a_max, 0.99 * tmin)\n",
    "    if a_min is None:\n",
    "        a_min = 0.0  # nonnegative shift is typical; set negative if you want\n",
    "    if not (a_min < a_max):\n",
    "        a_min = 0.0; a_max = 0.9 * tmin\n",
    "\n",
    "    # objective in terms of 'a': SSE after optimal c(a)\n",
    "    def sse_of_a(a):\n",
    "        c, yhat, sse = _fit_c_given_a(t, y, a)\n",
    "        if not np.isfinite(sse):\n",
    "            return np.inf\n",
    "        return sse\n",
    "\n",
    "    a_star = _golden_section(sse_of_a, a_min, a_max, tol=1e-6, maxit=300)\n",
    "    c_star, yhat_star, sse_star = _fit_c_given_a(t, y, a_star)\n",
    "\n",
    "    # Goodness-of-fit R^2\n",
    "    ybar = float(np.mean(y))\n",
    "    sst = float(np.sum((y - ybar)**2))\n",
    "    R2 = 1.0 - sse_star / sst if sst > 0 else np.nan\n",
    "\n",
    "    return c_star, a_star, yhat_star, R2\n",
    "\n",
    "# ---------- Generate plots and a fit-parameter table ----------\n",
    "fit_rows = []\n",
    "for n, dfn in S.groupby(\"n\"):\n",
    "    dfn = dfn.sort_values(\"t\")\n",
    "    tt = dfn[\"t\"].to_numpy()\n",
    "    yy = dfn[\"LB_tr\"].to_numpy()\n",
    "\n",
    "    if len(tt) < 2:\n",
    "        # Not enough points to fit; just plot the data\n",
    "        fig, ax = plt.subplots(figsize=(4.4, 3.2))\n",
    "        ax.plot(tt, yy, \"o-\", lw=1.6, label=r\"$\\mathrm{LB}_{\\rm tr}$\")\n",
    "        ax.set_xlabel(\"copies $t$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{LB}_{\\rm tr}$\")\n",
    "        ax.grid(alpha=0.25, linestyle=\":\", linewidth=0.8)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"lbtr_vs_t_n{int(n)}_offsetfit.pdf\")\n",
    "        plt.close(fig)\n",
    "        fit_rows.append({\"n\": int(n), \"c\": np.nan, \"a\": np.nan, \"R2\": np.nan, \"num_points\": len(tt)})\n",
    "        continue\n",
    "\n",
    "    # Fit y ≈ c / sqrt(t - a)\n",
    "    c, a, yhat, R2 = fit_offset_c_over_sqrt_t(tt, yy)\n",
    "\n",
    "    # Smooth curve for plotting\n",
    "    t_plot = np.linspace(min(tt), max(tt), 300)\n",
    "    t_plot = t_plot[t_plot > a + 1e-9]  # domain guard\n",
    "    y_plot = c / np.sqrt(t_plot - a)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(4.4, 3.2))\n",
    "    ax.plot(tt, yy, \"o-\", lw=1.6, label=r\"$\\mathrm{LB}_{\\rm tr}$\")\n",
    "    ax.plot(t_plot, y_plot, \"--\", lw=1.4,\n",
    "            label=fr\"fit $c/\\sqrt{{t-a}}$, $c={c:.3g}$, $a={a:.3g}$, $R^2={R2:.3f}$\")\n",
    "    ax.set_xlabel(\"copies $t$\")\n",
    "    ax.set_ylabel(r\"$\\mathrm{LB}_{\\rm tr}$\")\n",
    "    ax.set_xlim(min(tt)*0.95, max(tt)*1.05)\n",
    "    ax.grid(alpha=0.25, linestyle=\":\", linewidth=0.8)\n",
    "    ax.legend(loc=\"upper right\", frameon=False)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"lbtr_vs_t_n{int(n)}_offsetfit.pdf\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fit_rows.append({\"n\": int(n), \"c\": float(c), \"a\": float(a), \"R2\": float(R2), \"num_points\": int(len(tt))})\n",
    "\n",
    "# Save per-n fit parameters\n",
    "pd.DataFrame(fit_rows).to_csv(\"fit_params_offset_model.csv\", index=False)\n",
    "print(\"Done: lbtr_vs_t_n*_offsetfit.pdf, fit_params_offset_model.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2f73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc352ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72bae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
